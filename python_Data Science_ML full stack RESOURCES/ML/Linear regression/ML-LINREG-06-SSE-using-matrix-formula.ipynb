{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Consider a multiple linear regression model with k independent predictor variables $x_1, . . . ,x_k$ and one response variable y.\n",
    " \n",
    "$\\large y = β_0 + β_1x_1 + · · · + β_kx_k + \\epsilon $\n",
    "\n",
    "#### Suppose, we have n observations on the k + 1 variables.\n",
    "$ \\large y_i = β_0 + β_1{x_i}_1 + · · · + β_k{x_i}_k + \\epsilon_i$,     i= 1, . . . ,n\n",
    "\n",
    "#### think of the observations as points in (k +1) - dimensional space\n",
    "__linear trend__ $ y = \\beta_0 + \\beta_1x $\n",
    "\n",
    "Estimating the intercept and the slope of this line. That is, we seek estimators $\\hat{β}_0$ and $\\hat{\\beta}_1$ such that\n",
    "\n",
    "\n",
    "$ \\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1x $\n",
    "\n",
    "__ minimize__ $ SSE = \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2 $\n",
    "\n",
    "Substituting the value of $\\hat{y}$ into the equation for SSE we see that SSE can be viewed as a\n",
    "function of $\\hat{β}_0$ and $\\hat{β}_1$\n",
    "\n",
    "__Our goal__ in least-squares regression is to fit a hyper-plane into (k + 1)-dimensional\n",
    "space that minimizes the sum of squared residuals.\n",
    "\n",
    "\n",
    "SSE($\\beta_0, \\beta_1$) = $ \\sum_{i=1}^{n} e_i^2 =  \\sum_{i=1}^{n}(y_i - \\beta_0 - \\sum_{i=1}^{k}\\beta_j{x_i}_j)^2$   \n",
    "\n",
    "Take __derivatives__ with respect to the model parameters $β_0, . . . ,β_k$, set them equal to zero and derive the least-squares normal equations that our parameter estimates $β_0, . . . , β_k$ would have to fulfill\n",
    "\n",
    "\n",
    "$ n\\hat{\\beta}_0 + \\hat{\\beta}_1\\sum_{i=1}^n{x_i}_1 + \\hat{\\beta}_2\\sum_{i=1}{x_i}_2^n $\n",
    "\n",
    "#### the SSE equation is\n",
    "$ SSE(\\beta_0, \\beta_1) = \\sum_{i=1}^{n}(y_i - \\beta_0 - \\beta_j{x_i})^2$ \n",
    "\n",
    "#### partial derivative wrt $\\beta_0$\n",
    "\n",
    "$$ \n",
    "\\frac{d}{d{\\beta}_0}SSE(\\beta_0, \\beta_1) = \\sum_{i=1}^{n} (y_i - \\beta_0 - \\beta_1{x_i}). (-2)\n",
    "$$\n",
    "$$\n",
    "= -2\\sum_{i=1}^{n} (y_i - \\beta_0 - \\beta_1{x_i})\n",
    "= -2\\sum_{i=1}^{n}y_i + 2\\sum_{i=1}^{n}\\beta_0 + 2\\sum_{i=1}^{n}\\beta_1{x_i})\n",
    "= -2n\\bar{y} + 2n\\beta_0 + 2n{\\beta}_1\\bar{x} ----> (1)\n",
    "$$\n",
    "\n",
    "\n",
    "#### partial derivative wrt $\\beta_1$\n",
    "\n",
    "$$ \n",
    "\\frac{d}{d{\\beta}_1}SSE(\\beta_0, \\beta_1) = \\sum_{i=1}^{n} (y_i - \\beta_0 - \\beta_1{x_i}). (-2x_i)\n",
    "$$\n",
    "$$\n",
    "= -2\\sum_{i=1}^{n} (y_i - \\beta_0 - \\beta_1{x_i})x_i\n",
    "= -2\\sum_{i=1}^{n}x_iy_i + 2\\beta_0\\sum_{i=1}^{n}x_i + 2\\beta_1\\sum_{i=1}^{n}{x_i}^2\n",
    " ----> (2)\n",
    "$$\n",
    "\n",
    "#### from the equation (1),\n",
    "\n",
    "$$ \n",
    "\\frac{d}{d{\\beta}_0}SSE(\\beta_0, \\beta_1) = 0\n",
    "$$\n",
    "\n",
    "this means \n",
    "\n",
    "$$ -2n\\bar{y} + 2n\\beta_0 + 2n{\\beta}_1\\bar{x} = 0 $$\n",
    "\n",
    "$$ \\beta_0 = \\bar{y} - \\beta_1.\\bar{x} $$\n",
    "\n",
    "\n",
    "#### from the equation (2),\n",
    "$$ \\frac{d}{d{\\beta}_1}SSE(\\beta_0, \\beta_1) = 0 $$\n",
    "\n",
    "implies\n",
    "\n",
    "$$-2\\sum_{i=1}^{n}x_iy_i + 2\\beta_0\\sum_{i=1}^{n}x_i + 2\\beta_1\\sum_{i=1}^{n}{x_i}^2$$\n",
    "\n",
    "$$-\\sum_{i=1}^{n}x_iy_i + \\beta_0\\sum_{i=1}^{n}x_i + \\beta_1\\sum_{i=1}^{n}{x_i}^2$$\n",
    "\n",
    "\n",
    "$$-\\sum_{i=1}^{n}x_iy_i + (\\bar{y} - \\beta_1.\\bar{x})\\sum_{i=1}^{n}x_i + \\beta_1\\sum_{i=1}^{n}{x_i}^2$$\n",
    "\n",
    "$$-\\sum_{i=1}^{n}x_iy_i + \\bar{y}\\sum_{i=1}^{n}x_i - \\beta_1.\\bar{x}\\sum_{i=1}^{n}x_i + \\beta_1\\sum_{i=1}^{n}{x_i}^2$$\n",
    "\n",
    "So that, \n",
    "$$ \\beta_1.\\bar{x}\\sum_{i=1}^{n}x_i - \\beta_1\\sum_{i=1}^{n}{x_i}^2 = \\bar{y}\\sum_{i=1}^{n}x_i -\\sum_{i=1}^{n}x_iy_i  $$ \n",
    "\n",
    "$$ \\beta_1(\\bar{x}\\sum_{i=1}^{n}x_i - \\sum_{i=1}^{n}{x_i}^2) = \\bar{y}\\sum_{i=1}^{n}x_i -\\sum_{i=1}^{n}x_iy_i  $$ \n",
    "\n",
    "Thus we find,\n",
    "\n",
    "$$ \\beta_1 = \\frac{\\bar{y}\\sum_{i=1}^{n}x_i -\\sum_{i=1}^{n}x_iy_i}{\\bar{x}\\sum_{i=1}^{n}x_i - \\sum_{i=1}^{n}{x_i}^2} $$\n",
    "\n",
    "$$ \\beta_1 = \\frac{n\\bar{y}\\bar{x} -\\sum_{i=1}^{n}x_iy_i}{n\\bar{x}^2 - \\sum_{i=1}^{n}{x_i}^2} $$\n",
    "\n",
    "$$ \\beta_1 = \\frac{\\sum_{i=1}^{n}x_iy_i - n\\bar{y}\\bar{x}} {\\sum_{i=1}^{n}{x_i}^2 - n\\bar{x}^2} $$\n",
    "\n",
    "- With a bit of algebra, \n",
    "- we can write the numberator as\n",
    "$$ \\sum_{i=1}^{n}x_iy_i - n\\bar{y}\\bar{x} = \\sum_{i=1}^{n}x_iy_i - \\sum_{i=1}^{n}\\bar{x}\\bar{y} $$\n",
    "\n",
    "$$ = \\sum_{i=1}^{n}(x_i -\\bar{x})(y_i - \\bar{y}) = {S_X}_Y $$\n",
    "\n",
    "- we can write the denominator as\n",
    "\n",
    "$$ \\sum_{i=1}^{n}{x_i}^2 - n\\bar{x}^2 = \\sum_{i=1}^{n}{x_i}^2 - \\sum_{i=1}^{n}\\bar{x}^2 = \\sum_{i=1}^{n}({x_i}^2 - \\bar{x}^2) = {S_X}_X$$\n",
    "\n",
    "So we can write\n",
    "\n",
    "$$ \\beta_1 = \\frac{{S_X}_Y}{{S_X}_X} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beta coefficients using matrix algebra\n",
    "\n",
    "__minimize the sum of the squared error term__ $Σ(y_i – f(x_i))^2$, which we’ll write as \n",
    "    (y-XB)'(y-XB) using linear algebra.\n",
    "    \n",
    "__The True Model__\n",
    "- Let X be an n × k matrix where we have observations on k independent variables for n\n",
    "observations. Since our model will usually contain a constant term, one of the columns in\n",
    "the X matrix will contain only ones. This column should be treated exactly the same as any\n",
    "other column in the X matrix.\n",
    "- Let y be an n × 1 vector of observations on the dependent variable.\n",
    "- Let $\\epsilon$ be an n × 1 vector of disturbances or errors.\n",
    "- Let β be an k × 1 vector of unknown population parameters that we want to estimate.\n",
    "    \n",
    "$${\\begin{bmatrix} Y_1 \\\\ Y_2 \\\\ \\vdots \\\\ \\vdots \\\\Y_n \\end{bmatrix}}_{n \\> \\times \\> 1}\n",
    "= \\begin\n",
    "{bmatrix} \n",
    "1 \\quad {X_1}_1 \\quad {X_2}_1 \\quad \\dots \\quad {X_k}_1 \\\\\n",
    "1 \\quad {X_1}_2 \\quad {X_2}_2 \\quad \\dots \\quad {X_k}_2 \\\\\n",
    "\\dots \\quad \\dots \\quad \\dots \\quad \\dots \\quad \\dots  \\\\\n",
    "\\dots \\quad \\dots \\quad \\dots \\quad \\dots \\quad \\dots  \\\\\n",
    "1 \\quad {X_1}_n \\quad {X_2}_2 \\quad \\dots \\quad {X_k}_n \\\\\n",
    "\\end{bmatrix}_{n \\> \\times \\> k}\n",
    ".\n",
    "{\\begin{bmatrix} \\beta_1 \\\\ \\beta_2 \\\\ \\vdots \\\\ \\vdots \\\\\\beta_n \\end{bmatrix}}_{k \\> \\times \\> 1}\n",
    "+\n",
    "{\\begin{bmatrix} \\epsilon_1 \\\\ \\epsilon_2 \\\\ \\vdots \\\\ \\vdots \\\\\\epsilon_n \\end{bmatrix}}_{n \\> \\times \\> 1}\n",
    "$$\n",
    "\n",
    "This can be rewritten more simply as:\n",
    "$$ y = Xβ + \\epsilon $$\n",
    "\n",
    "The model has a \n",
    "- systematic component (Xβ) \n",
    "- stochastic component $(\\epsilon).$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Criteria for Estimates__\n",
    "\n",
    "find the estimator $\\hatβ$ that minimizes the sum of squared residuals $\\sum e_i^2$\n",
    "\n",
    "The vector of residuals e is given by:\n",
    "$e = y − Xβ$\n",
    "\n",
    "The sum of squared residuals (RSS) is $e^\\top e$\n",
    "\n",
    "\n",
    "*** It is important to note that this is very different from $ee^\\top$\n",
    "– the variance-covariance matrix of residuals.\n",
    "\n",
    "$$\n",
    "{\\begin{bmatrix} e_1 \\quad e_2 \\quad \\dots \\quad \\dots \\quad e_n \\end{bmatrix}}_{1 \\> \\times \\> n}\n",
    "{\\begin{bmatrix} e_1 \\\\ e_2 \\\\ \\vdots \\\\ \\vdots \\\\ e_n \\end{bmatrix}}_{n \\> \\times \\> 1}\n",
    "= \n",
    "{\\begin{bmatrix} e_1*e_1 + e_2*e_2 + \\dots \\dots e_n*e_n \\end{bmatrix}}_{1 \\> \\times \\> 1}\n",
    "$$\n",
    "\n",
    "we can write the sum of squared residuals as:\n",
    "\n",
    "$$\n",
    "e^\\top e = (y − Xβ)^\\top (y − Xβ)\n",
    "= y^\\top y - β^\\top{X}^\\top y - y^\\top Xβ + β^\\top{X}^\\top Xβ\n",
    "= y^\\top y - 2β^\\top{X}^\\top y + β^\\top{X}^\\top Xβ\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{d}{d\\beta}e^\\top e = 0\n",
    "$$\n",
    "$$\n",
    "- 2{X}^\\top y + 2{X}^\\top Xβ = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "({X}^\\top X)β = {X}^\\top y \n",
    "$$\n",
    "\n",
    "$$\n",
    "β = ({X}^\\top X)^{-1} ({X}^\\top y )\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
